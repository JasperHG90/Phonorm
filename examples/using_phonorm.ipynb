{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using phonorm\n",
    "\n",
    "This notebook shows you how you can load pre-trained phonorm models and use them to predict the pronunciation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "# We assume that you are in the '../examples' directory\n",
    "import os\n",
    "path = os.getcwd().replace('\\\\examples', '')\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load the functions necessary to process the data\n",
    "from phonorm.utilities import create_mapping, tensor_from_pair, one_hot_encode, decode_from_ohe\n",
    "from phonorm.tests import check_ohe\n",
    "from phonorm.evaluate import plot_model_history, decode_sequence, evaluate_bleu, plot_bleu\n",
    "from phonorm.Seq2Seq import Seq2Seq\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the `cmudict (single)` dataset and preprocess it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "pairs = np.load(\"data/preprocessed/cmudict_singlechar_train.npy\")\n",
    "\n",
    "# Create mapping\n",
    "input_lang, output_lang = create_mapping(\"input\", \"output\", pairs)\n",
    "\n",
    "# Sample training pairs (len(pairs) == entire training data set)\n",
    "ml = len(pairs)\n",
    "random.seed(245)\n",
    "pairs_array = [random.choice(pairs) for i in range(ml)]\n",
    "\n",
    "# Split array into input / output vectors\n",
    "input_array = [pair[0] for pair in pairs_array]\n",
    "output_array = [pair[1] for pair in pairs_array]\n",
    "\n",
    "## One-hot encoding\n",
    "encoder_in_ohe = one_hot_encode(input_array, input_lang)\n",
    "decoder_in_ohe = one_hot_encode(output_array, output_lang)\n",
    "decoder_out_ohe = one_hot_encode(output_array, output_lang, one_timestep_ahead=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded and 'target decoded' should be the same\n",
      "\n",
      "---- Example 0\n",
      "Input: crumb, decoded: crumb\n",
      "Output: krahm, decoded: krahm, target decoded: krahm\n",
      "\n",
      "\n",
      "---- Example 1\n",
      "Input: caspers, decoded: caspers\n",
      "Output: kaesperz, decoded: kaesperz, target decoded: kaesperz\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check if one-hot encoding works properly by sampling 2 random pairs\n",
    "check_ohe(pairs, input_lang, output_lang, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the encoder/decoder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the encoder/decoder model\n",
    "phonorm = Seq2Seq(512, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cmudict (single) model\n",
    "phonorm.load(\"models/cmudict/singlechar_model_10EP_H512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ehrahn'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can now use the predict() function \n",
    "phonorm.predict(\"aaron\") # The first run takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Donald Trump went to North Korea today to talk about the denuclearisation of the Korean peninsula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_out = [phonorm.predict(word.lower()) for word in sentence.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daanahld trahmp wehnt tuw naorth kaoriyah tahdey tuw taok ahbawt dhey diynuwklerehseyshahn aof dhey kaoriyahn pehnihnsuwlah'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(sentence_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
