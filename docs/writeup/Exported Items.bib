
@inproceedings{khoury_phonetic_2015,
	title = {Phonetic normalization of microtext},
	doi = {10.1145/2808797.2809352},
	abstract = {Microtext normalization is the challenge of discovering the English words corresponding to the unusually-spelled words used in social-media messages and posts. In this paper, we propose a novel method for doing this by rendering both English and microtext words phonetically based on their spelling, and matching similar ones together. We present our algorithm to learn spelling-to-phonetic probabilities and to efficiently search the English language and match words together. Our results demonstrate that our system correctly handles many types of normalization problems.},
	booktitle = {2015 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	author = {Khoury, R.},
	month = aug,
	year = {2015},
	keywords = {Training data, Data mining, English language, English words, learning (artificial intelligence), Media, microtext, microtext phonetic normalization, natural language processing, normalization, phonetic, probability, Rendering (computer graphics), social media, social networking (online), social-media messages, social-media post, spelling-to-phonetic probability learning, text analysis, Training, Twitter, unusually-spelled words, wiktionary, word matching},
	pages = {1600--1601},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\jaspe\\Zotero\\storage\\2QAMWC37\\7403761.html:text/html}
}

@inproceedings{jahjah_word_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Word {Normalization} {Using} {Phonetic} {Signatures}},
	isbn = {978-3-319-34111-8},
	abstract = {Text normalization is the challenge of discovering the English words corresponding to the unusually-spelled words used in social-media messages and posts. In this paper, we detail a new word-searching strategy based on the idea of sounding out the consonants of the word. We describe our algorithm to extract the base consonant information from both miswritten and real words using a spelling and a phonetic approach. We then explain how this information is used to match similar words together. This strategy is shown to be time efficient as well as capable of correctly handling many types of normalization problems.},
	language = {en},
	booktitle = {Advances in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Jahjah, Vincent and Khoury, Richard and Lamontagne, Luc},
	editor = {Khoury, Richard and Drummond, Christopher},
	year = {2016},
	keywords = {Normalization, Social media, TheFreeDictionary, Wiktionary},
	pages = {180--185}
}

@inproceedings{wang_beam-search_2013,
	address = {Atlanta, Georgia},
	title = {A {Beam}-{Search} {Decoder} for {Normalization} of {Social} {Media} {Text} with {Application} to {Machine} {Translation}},
	url = {http://aclweb.org/anthology/N13-1050},
	urldate = {2018-12-28},
	booktitle = {Proceedings of the 2013 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Pidong and Ng, Hwee Tou},
	year = {2013},
	pages = {471--481},
	file = {Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\UVZLMRAY\\Wang and Ng - 2013 - A Beam-Search Decoder for Normalization of Social .pdf:application/pdf}
}

@inproceedings{aw_phrase-based_2006,
	address = {Stroudsburg, PA, USA},
	series = {{COLING}-{ACL} '06},
	title = {A {Phrase}-based {Statistical} {Model} for {SMS} {Text} {Normalization}},
	url = {http://dl.acm.org/citation.cfm?id=1273073.1273078},
	abstract = {Short Messaging Service (SMS) texts behave quite differently from normal written texts and have some very special phenomena. To translate SMS texts, traditional approaches model such irregularities directly in Machine Translation (MT). However, such approaches suffer from customization problem as tremendous effort is required to adapt the language model of the existing translation system to handle SMS text style. We offer an alternative approach to resolve such irregularities by normalizing SMS texts before MT. In this paper, we view the task of SMS normalization as a translation problem from the SMS language to the English language and we propose to adapt a phrase-based statistical MT model for the task. Evaluation by 5-fold cross validation on a parallel SMS normalized corpus of 5000 sentences shows that our method can achieve 0.80702 in BLEU score against the baseline BLEU score 0.6958. Another experiment of translating SMS texts from English to Chinese on a separate SMS text corpus shows that, using SMS normalization as MT preprocessing can largely boost SMS translation performance from 0.1926 to 0.3770 in BLEU score.},
	urldate = {2018-12-28},
	booktitle = {Proceedings of the {COLING}/{ACL} on {Main} {Conference} {Poster} {Sessions}},
	publisher = {Association for Computational Linguistics},
	author = {Aw, AiTi and Zhang, Min and Xiao, Juan and Su, Jian},
	year = {2006},
	pages = {33--40},
	file = {ACM Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\DDQGKY2D\\Aw et al. - 2006 - A Phrase-based Statistical Model for SMS Text Norm.pdf:application/pdf}
}

@article{doval_performance_2018,
	title = {On the performance of phonetic algorithms in microtext normalization},
	volume = {113},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417418304305},
	doi = {10.1016/j.eswa.2018.07.016},
	abstract = {User–generated content published on microblogging social networks constitutes a priceless source of information. However, microtexts usually deviate from the standard lexical and grammatical rules of the language, thus making its processing by traditional intelligent systems very difficult. As an answer, microtext normalization consists in transforming those non–standard microtexts into standard well–written texts as a preprocessing step, allowing traditional approaches to continue with their usual processing. Given the importance of phonetic phenomena in non–standard text formation, an essential element of the knowledge base of a normalizer would be the phonetic rules that encode these phenomena, which can be found in the so–called phonetic algorithms. In this work we experiment with a wide range of phonetic algorithms for the English language. The aim of this study is to determine the best phonetic algorithms within the context of candidate generation for microtext normalization. In other words, we intend to find those algorithms that taking as input non–standard terms to be normalized allow us to obtain as output the smallest possible sets of normalization candidates which still contain the corresponding target standard words. As it will be stated, the choice of the phonetic algorithm will depend heavily on the capabilities of the candidate selection mechanism which we usually find at the end of a microtext normalization pipeline. The faster it can make the right choices among big enough sets of candidates, the more we can sacrifice on the precision of the phonetic algorithms in favour of coverage in order to increase the overall performance of the normalization system.},
	urldate = {2018-12-28},
	journal = {Expert Systems with Applications},
	author = {Doval, Yerai and Vilares, Manuel and Vilares, Jesús},
	month = dec,
	year = {2018},
	keywords = {Twitter, Fuzzy matching, Microtext normalization, Phonetic algorithm, Texting},
	pages = {213--222},
	file = {ScienceDirect Snapshot:C\:\\Users\\jaspe\\Zotero\\storage\\F9WQUNQW\\S0957417418304305.html:text/html}
}

@article{zhang_segmenting_2017,
	title = {Segmenting {Chinese} {Microtext}: {Joint} {Informal}-{Word} {Detection} and {Segmentation} with {Neural} {Networks}},
	shorttitle = {Segmenting {Chinese} {Microtext}},
	url = {https://www.ijcai.org/proceedings/2017/591},
	abstract = {Electronic proceedings of IJCAI 2017},
	urldate = {2018-12-28},
	author = {Zhang, Meishan and Fu, Guohong and Yu, Nan},
	year = {2017},
	pages = {4228--4234},
	file = {Snapshot:C\:\\Users\\jaspe\\Zotero\\storage\\AFVKDELJ\\591.html:text/html}
}

@inproceedings{xue_normalizing_2011,
	title = {Normalizing {Microtext}.},
	abstract = {The use of computer mediated communication has resulted in a new form of written text - Microtext - which is very different from well-written text. Tweets and SMS messages, which have limited length and may contain misspellings, slang, or abbreviations, are two typical examples of microtext. Micro-text poses new challenges to standard natural language processing tools which are usually designed for well-written text. The objective of this work is to normalize microtext, in order to produce text that could be suitable for further treatment. We propose a normalization approach based on the source channel model, which incorporates four factors, namely an orthographic factor, a phonetic factor, a contextual factor and acronym expansion. Experiments show that our approach can normalize Twitter messages reasonably well, and it outperforms existing algorithms on a public SMS data set. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.},
	author = {Xue, Zhenzhen and Yin, Dawei and Davison, Brian},
	month = jan,
	year = {2011},
	file = {Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\NTZ2HNVX\\Xue et al. - 2011 - Normalizing Microtext..pdf:application/pdf}
}

@inproceedings{li_normalization_2012,
	title = {Normalization of {Text} {Messages} {Using} {Character}- and {Phone}-based {Machine} {Translation} {Approaches}},
	volume = {3},
	abstract = {There are many abbreviation and non-standard words in SMS and Twitter messages. They are problematic for text-to-speech (TTS) or language processing techniques for these data. A character-based machine translation (MT) approach was previously used for normalization of non-standard words. In this paper, we propose a two-stage translation method to leverage phonetic information, where non-standard words are first
translated to possible pronunciations, which are then translated to standard words. We further combine it with the single-step character-based translation module. Our experiments show that our proposed method significantly outperforms previous results in both n-best coverage and 1-best accuracy.},
	author = {Li, Chen and Liu, Yang},
	month = sep,
	year = {2012},
	file = {Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\HQBV3JE5\\Li and Liu - 2012 - Normalization of Text Messages Using Character- an.pdf:application/pdf}
}

@article{pennell_normalization_2014,
	title = {Normalization of {Informal} {Text}},
	volume = {28},
	issn = {0885-2308},
	url = {http://dx.doi.org/10.1016/j.csl.2013.07.001},
	doi = {10.1016/j.csl.2013.07.001},
	abstract = {This paper describes a noisy-channel approach for the normalization of informal text, such as that found in emails, chat rooms, and SMS messages. In particular, we introduce two character-level methods for the abbreviation modeling aspect of the noisy channel model: a statistical classifier using language-based features to decide whether a character is likely to be removed from a word, and a character-level machine translation model. A two-phase approach is used; in the first stage the possible candidates are generated using the selected abbreviation model and in the second stage we choose the best candidate by decoding using a language model. Overall we find that this approach works well and is on par with current research in the field.},
	number = {1},
	urldate = {2018-12-28},
	journal = {Comput. Speech Lang.},
	author = {Pennell, Deana L. and Liu, Yang},
	month = jan,
	year = {2014},
	keywords = {NLP applications, Noisy text, Text normalization},
	pages = {256--277}
}

@article{bisani_joint-sequence_2008,
	title = {Joint-sequence models for grapheme-to-phoneme conversion},
	volume = {50},
	issn = {0167-6393},
	url = {http://www.sciencedirect.com/science/article/pii/S0167639308000046},
	doi = {10.1016/j.specom.2008.01.002},
	abstract = {Grapheme-to-phoneme conversion is the task of finding the pronunciation of a word given its written form. It has important applications in text-to-speech and speech recognition. Joint-sequence models are a simple and theoretically stringent probabilistic framework that is applicable to this problem. This article provides a self-contained and detailed description of this method. We present a novel estimation algorithm and demonstrate high accuracy on a variety of databases. Moreover, we study the impact of the maximum approximation in training and transcription, the interaction of model size parameters, n-best list generation, confidence measures, and phoneme-to-grapheme conversion. Our software implementation of the method proposed in this work is available under an Open Source license.},
	number = {5},
	urldate = {2019-01-03},
	journal = {Speech Communication},
	author = {Bisani, Maximilian and Ney, Hermann},
	month = may,
	year = {2008},
	keywords = {Grapheme-to-phoneme, Joint-sequence model, Letter-to-sound, Phonemic transcription, Pronunciation modeling},
	pages = {434--451},
	file = {ScienceDirect Snapshot:C\:\\Users\\jaspe\\Zotero\\storage\\VV3YWP8W\\S0167639308000046.html:text/html;Submitted Version:C\:\\Users\\jaspe\\Zotero\\storage\\6Z44XY3I\\Bisani and Ney - 2008 - Joint-sequence models for grapheme-to-phoneme conv.pdf:application/pdf}
}

@inproceedings{jaitly_rnn_2017,
	title = {An {RNN} {Model} of {Text} {Normalization}},
	url = {https://arxiv.org/pdf/1611.00068.pdf},
	urldate = {2019-01-03},
	author = {Jaitly, Navdeep and Sproat, Richard},
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\W8QUSVMN\\Jaitly and Sproat - 2017 - An RNN Model of Text Normalization.pdf:application/pdf}
}

@inproceedings{lopez-ludena_architecture_2012,
	title = {Architecture for {Text} {Normalization} using {Statistical} {Machine} {Translation} techniques},
	abstract = {This paper proposes an architecture, based on statistical machine translation, for developing the text normalization module of a text to speech conversion system. The main target is to generate a language independent text normalization module, based on data and flexible enough to deal with all situations presented in this task. The proposed architecture is composed by three main modules: a tokenizer module for splitting the text input into a token graph (tokenization), a phrase-based translation module (token translation) and a postprocessing module for removing some tokens. This paper presents initial experiments for numbers and abbreviations. The very good results obtained validate the proposed architecture.},
	author = {López-Ludeña, Verónica and San-Segundo, Rubén and Montero, J. M. and Barra-Chicote, Roberto and Lorenzo, Javier Mateos},
	year = {2012},
	keywords = {Abbreviations, Experiment, Lexical analysis, Speech synthesis, Statistical machine translation, Text normalization, Tokenization (data security)},
	file = {Full Text PDF:C\:\\Users\\jaspe\\Zotero\\storage\\5BNJKXGF\\López-Ludeña et al. - 2012 - Architecture for Text Normalization using Statisti.pdf:application/pdf}
}

@inproceedings{satapathy_phonetic-based_2017,
	title = {Phonetic-{Based} {Microtext} {Normalization} for {Twitter} {Sentiment} {Analysis}},
	doi = {10.1109/ICDMW.2017.59},
	abstract = {The proliferation of Web 2.0 technologies and the increasing use of computer-mediated communication resulted in a new form of written text, termed microtext. This poses new challenges to natural language processing tools which are usually designed for well-written text. This paper proposes a phonetic-based framework for normalizing microtext to plain English and, hence, improve the classification accuracy of sentiment analysis. Results demonstrated that there is a high ({\textgreater}0.8) similarity index between tweets normalized by our model and tweets normalized by human annotators in 85.31\% of cases, and that there is an accuracy increase of {\textgreater}4\% in terms of polarity detection after normalization.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Data} {Mining} {Workshops} ({ICDMW})},
	author = {Satapathy, R. and Guerreiro, C. and Chaturvedi, I. and Cambria, E.},
	month = nov,
	year = {2017},
	keywords = {classification accuracy, computer mediated communication, Error correction, Knowledge based systems, Microtext analysis, microtext normalization, natural language processing tools, pattern classification, phonetic-based framework, plain English, Semantics, sentiment analysis, Sentiment analysis, similarity index, social networking (online), speech processing, Terminology, Text normalization, tweets, Twitter, twitter sentiment analysis},
	pages = {407--413},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\jaspe\\Zotero\\storage\\FDZSLCMH\\8215691.html:text/html}
}

@inproceedings{khoury_microtext_2015,
	title = {Microtext normalization using probably-phonetically-similar word discovery},
	doi = {10.1109/WiMOB.2015.7347988},
	abstract = {Microtext normalization is the challenge of discovering the English words corresponding to the unusually-spelled words used in social-media messages and posts. In this paper, we propose a novel method for doing this by rendering both English and microtext words phonetically based on their spelling, and matching similar ones together. We present our algorithm to learn spelling-to-phonetic probabilities and to efficiently search the English language and match words together. Our results demonstrate that our system correctly handles many types of normalization problems.},
	booktitle = {2015 {IEEE} 11th {International} {Conference} on {Wireless} and {Mobile} {Computing}, {Networking} and {Communications} ({WiMob})},
	author = {Khoury, R.},
	month = oct,
	year = {2015},
	keywords = {Conferences, Dictionaries, Electronic publishing, Encyclopedias, English language, Internet, linguistics, microtext, microtext normalization, microtext word, normalization, phonetic, probability, rendering, social media, social networking (online), social-media message, speech processing, spelling-to-phonetic probability, text analysis, wiktionary, word discovery},
	pages = {384--391},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\jaspe\\Zotero\\storage\\Q6JLSE6Z\\7347988.html:text/html}
}